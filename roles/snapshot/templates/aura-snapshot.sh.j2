#!/bin/bash
# AURA Blockchain Snapshot Script
# Generated by Ansible - do not edit directly

set -euo pipefail

# Configuration
AURA_HOME="{{ snapshot_aura_home }}"
AURA_SERVICE="{{ snapshot_aura_service }}"
CHAIN_ID="{{ snapshot_chain_id }}"
SNAPSHOT_DIR="{{ snapshot_dir }}"
RETENTION_DAYS="{{ snapshot_retention_days }}"
COMPRESSION="{{ snapshot_compression }}"

{% if snapshot_r2_upload_enabled %}
# R2 Upload configuration
R2_BUCKET="{{ snapshot_r2_bucket }}"
R2_ENDPOINT="{{ snapshot_r2_endpoint }}"
export AWS_ACCESS_KEY_ID="{{ snapshot_r2_access_key_id }}"
export AWS_SECRET_ACCESS_KEY="{{ snapshot_r2_secret_access_key }}"
{% endif %}

# Expand home directory
AURA_HOME="${AURA_HOME/#\~/$HOME}"

# Get current timestamp and block height
TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")
HEIGHT=$(curl -s http://127.0.0.1:26657/status 2>/dev/null | jq -r '.result.sync_info.latest_block_height' || echo "unknown")

SNAPSHOT_NAME="${CHAIN_ID}_${HEIGHT}_${TIMESTAMP}"
SNAPSHOT_FILE="${SNAPSHOT_DIR}/${SNAPSHOT_NAME}.tar"

echo "=========================================="
echo "AURA Snapshot - $(date -u)"
echo "Chain ID: ${CHAIN_ID}"
echo "Block Height: ${HEIGHT}"
echo "=========================================="

# Create snapshot directory if it doesn't exist
mkdir -p "${SNAPSHOT_DIR}"

# Stop the node
echo "Stopping AURA service..."
sudo systemctl stop "${AURA_SERVICE}" || true

# Wait for service to stop
sleep 5

# Create tarball of data directory
echo "Creating snapshot..."
cd "${AURA_HOME}"
tar -cf "${SNAPSHOT_FILE}" data/

# Start the node back up
echo "Starting AURA service..."
sudo systemctl start "${AURA_SERVICE}"

# Compress the snapshot
echo "Compressing snapshot with ${COMPRESSION}..."
case "${COMPRESSION}" in
    lz4)
        lz4 -9 --rm "${SNAPSHOT_FILE}" "${SNAPSHOT_FILE}.lz4"
        SNAPSHOT_FILE="${SNAPSHOT_FILE}.lz4"
        ;;
    gzip)
        gzip -9 "${SNAPSHOT_FILE}"
        SNAPSHOT_FILE="${SNAPSHOT_FILE}.gz"
        ;;
    zstd)
        zstd -19 --rm "${SNAPSHOT_FILE}"
        SNAPSHOT_FILE="${SNAPSHOT_FILE}.zst"
        ;;
    *)
        echo "Unknown compression: ${COMPRESSION}"
        ;;
esac

echo "Snapshot created: ${SNAPSHOT_FILE}"
ls -lh "${SNAPSHOT_FILE}"

{% if snapshot_r2_upload_enabled %}
# Upload to R2
echo "Uploading to R2..."
aws s3 cp "${SNAPSHOT_FILE}" "s3://${R2_BUCKET}/${CHAIN_ID}/snapshots/$(basename ${SNAPSHOT_FILE})" \
    --endpoint-url "${R2_ENDPOINT}"

# Update latest.json
cat > /tmp/latest.json <<EOF
{
    "chain_id": "${CHAIN_ID}",
    "height": ${HEIGHT},
    "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "file": "$(basename ${SNAPSHOT_FILE})",
    "size": $(stat -c%s "${SNAPSHOT_FILE}"),
    "compression": "${COMPRESSION}"
}
EOF

aws s3 cp /tmp/latest.json "s3://${R2_BUCKET}/${CHAIN_ID}/snapshots/latest.json" \
    --endpoint-url "${R2_ENDPOINT}"
rm -f /tmp/latest.json
echo "R2 upload complete"
{% endif %}

# Clean up old snapshots
echo "Cleaning up snapshots older than ${RETENTION_DAYS} days..."
find "${SNAPSHOT_DIR}" -name "${CHAIN_ID}_*" -type f -mtime +${RETENTION_DAYS} -delete

echo "=========================================="
echo "Snapshot complete!"
echo "=========================================="
